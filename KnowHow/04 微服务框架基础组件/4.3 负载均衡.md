#### 负载均衡

从横向拆分角度讲，分布式是指将不同的业务分布在不同的地方，而集群指的是将几台服务器集中在一起实现同一业务。分布式中的每一个节点都可以做集群，但集群并不一定是分布式的。

集群概念的提出同时考虑到了分布式系统中性能和可用性的问题，一方面，集群的负载均衡机制可以将业务请求分摊到多台单机性能不一定出众的服务器，另一方面，集群的容错机制确保当集群中的某台机器无法正常提供服务时整体集群仍然可用。而负载均衡简单讲就是将请求分摊到多个操作单元上进行执行。

负载均衡建立在现有网络结构上，提供了一种廉价、有效、透明的方法扩展服务器的带宽、增加吞吐量、加强网络数据处理能力，以及提高网络的灵活性。以各种负载均衡算法为基础的分发策略决定了负载均衡的效果，根据服务器地址列表所存放的位置可以分为两大类，一类是服务器负载均衡，另一类是客服端负载均衡。

##### 1. 服务端负载均衡

客户端发送请求到负载均衡器LB，负载均衡器负责将接收到的各个请求转发到运行中的某台服务节点上，然后接收到请求的微服务做响应处理，常见的有Apache、Nginx、HAProxy。

![服务端负载均衡](..\00 common\images\04\服务端负载均衡.png)

其实现机制比较忙简单，只需要在客服端与各个微服务实例之间架设集中式的负载均衡器即可，负载均衡器动态获取各个微服务运行时的信息，决定负载均衡的目标服务，若负载均衡器检测到某个服务已经不可用的时候就会自动移除该服务。

注意，负载均衡器运行在一台独立的服务器上并充当代理的作用，同时，需要注意的是当服务请求越来越大的时候，负载均衡器就会成为系统的瓶颈，同时若负载均衡器自身发生失败时，整体服务的调用都将发生失败。

##### 2. 客户端负载均衡

客户端负载均衡机制的主要优势就是不会出现集中式负载均均衡所产生的瓶颈问题，因为每个客户端都有自己的负载均衡器，负载均衡器失败也不会造成严重的后果，但是运行时的信息在多个负载均衡器之间进行服务配置信息的传递会在一定程度上加重网络流量负载。  

![客户端负载均衡](..\00 common\images\04\客户端负载均衡.png)

实现上，需要在客服端程序里面自己设定一个调度算法，在向服务器发起请求的时候，先执行调度算法计算出目标服务器地址，具体与原理如下图分析：

![客户端负载均衡算法](..\00 common\images\04\客户端负载均衡算法.png)

其另一种典型的实现方式是把Nginx等能够实现代理功能的负载服务器部署到运行微服务的一台机器上。这时需要考虑实施成本和维护性问题。客户端负载均衡比较适合于客户端具有成熟的调度库函数、算法以及API的工具和框架。

##### 3. 负载均衡算法

大致可以分为两大类，即静态负载均衡算法和动态负载均衡算法。

**静态负载均衡算法**

主要指的是各种随机算法和轮询算法。

- 轮询算法：

将请求按顺序轮流地分配到后端服务器上，它均衡地对待后端的每一台服务器，而不关心服务器实际的连接数和当前的系统负载。

- 随机算法：

  通过系统的随机算法，根据后端服务器的列表大小值来随机选取其中的一台服务器进行访问。由概率统计理论可以得知，随着客户端调用服务端的次数增多，其实际效果越来越接近于平均分配调用量到后端的每一台服务器，也就是轮询的结果。

- 加权轮询算法：

  不同的后端服务器可能机器的配置和当前系统的负载并不相同，因此它们的抗压能力也不相同。给配置高、负载低的机器配置更高的权重，让其处理更多的请；而配置低、负载高的机器，给其分配较低的权重，降低其系统负载，加权轮询能很好地处理这一问题，并将请求顺序且按照权重分配到后端。

**动态负载均衡算法**

根据服务器的实时性能分配连接是常见的动态策略。所有涉及权重的静态算法都可以转变为动态算法。常见的有以下几种：

- 最小连接数算法：

  比较灵活和智能，由于后端服务器的配置不尽相同，对于请求的处理有快有慢，它是根据后端服务器当前的连接情况，动态地选取其中当前积压连接数最少的一台服务器来处理当前的请求，尽可能地提高后端服务的利用效率，将负责合理地分流到每一台服务器。

- 源地址哈希算法：

  根据获取客户端的IP地址，通过哈希函数计算得到的一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是客服端要访问服务器的序号。采用源地址哈希法进行负载均衡，同一IP地址的客户端，当后端服务器列表不变时，它每次都会映射到同一台后端服务器进行访问。